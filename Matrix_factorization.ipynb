{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "from collections import defaultdict\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(r'./data/df.csv');\n",
    "df = df2.reset_index().drop(['index'], axis=1).melt(id_vars = ['objectId'])\n",
    "df.rename(columns = {'value':'counts', 'variable':'visitorIp'}, inplace = True)\n",
    "df['counts'].fillna(0, inplace=True)\n",
    "df['counts'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(object):\n",
    "\n",
    "    Regularization = Decimal(0.002)\n",
    "    BiasLearnRate = Decimal(0.001)\n",
    "    BiasReg = Decimal(0.002)\n",
    "\n",
    "    LearnRate = Decimal(0.001)\n",
    "\n",
    "\n",
    "    item_bias = None\n",
    "    user_bias = None\n",
    "    beta = 0.02\n",
    "\n",
    "    iterations = 0\n",
    "\n",
    "    def __init__(self, save_path, max_iterations=10):\n",
    "        self.save_path = save_path\n",
    "        self.user_factors = None\n",
    "        self.item_factors = None\n",
    "        self.item_counts = None\n",
    "        self.u_inx = None\n",
    "        self.i_inx = None\n",
    "        self.user_ids = None\n",
    "        self.object_ids = None\n",
    "        self.rmse_values = {}\n",
    "\n",
    "        self.MAX_ITERATIONS = max_iterations\n",
    "        random.seed(42)\n",
    "\n",
    "        ensure_dir(save_path)\n",
    "\n",
    "    def initialize_factors(self, ratings, k=25):\n",
    "        self.user_ids = set(ratings['visitorIp'].values)\n",
    "        self.object_ids = set(ratings['objectId'].values)\n",
    "        self.item_counts = ratings[['objectId', 'counts']].groupby('objectId').count()\n",
    "        self.item_counts = self.item_counts.reset_index()\n",
    "\n",
    "        self.u_inx = {r: i for i, r in enumerate(self.user_ids)}\n",
    "        self.i_inx = {r: i for i, r in enumerate(self.object_ids)}\n",
    "\n",
    "        self.item_factors = np.full((len(self.i_inx), k), Decimal(0.1))\n",
    "        self.user_factors = np.full((len(self.u_inx), k), Decimal(0.1))\n",
    "\n",
    "        print(\"User factors: {}\".format(self.user_factors.shape))\n",
    "        print(\"Item factors: {}\".format(self.item_factors.shape))\n",
    "        self.user_bias = defaultdict(lambda: 0)\n",
    "        self.item_bias = defaultdict(lambda: 0)\n",
    "\n",
    "    def predict(self, user, item):\n",
    "\n",
    "        pq = np.dot(self.item_factors[item], self.user_factors[user].T)\n",
    "        b_ui = self.user_bias[user] + self.item_bias[item]\n",
    "        prediction = pq + b_ui\n",
    "\n",
    "        if prediction > 2:\n",
    "            prediction = 2\n",
    "        elif prediction < 1:\n",
    "            prediction = 0\n",
    "        return prediction\n",
    "\n",
    "    def build(self, ratings, params):\n",
    "\n",
    "        if params:\n",
    "            k = params['k']\n",
    "            self.save_path = params['save_path']\n",
    "\n",
    "        self.train(ratings, k)\n",
    "\n",
    "    def split_data(self, ratings):\n",
    "\n",
    "        users = set(ratings.loc[ratings['counts'] > 0.0]['visitorIp'].values)\n",
    "        train_data_len = int((len(users) * 70 / 100))\n",
    "\n",
    "        test_users = set(random.sample(list(users), (len(users) - train_data_len)))\n",
    "        train_users = users - test_users\n",
    "\n",
    "        train = ratings[ratings['visitorIp'].isin(train_users)]\n",
    "        test = ratings[ratings['visitorIp'].isin(test_users)]\n",
    "\n",
    "        return test, train\n",
    "\n",
    "    def meta_parameter_train(self, ratings_df):\n",
    "\n",
    "        for lr in [0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]:\n",
    "            self.Regularization = Decimal(0.002)\n",
    "            self.BiasReg = Decimal(0.002)\n",
    "\n",
    "            self.BiasLearnRate = Decimal(lr)\n",
    "            self.LearnRate = Decimal(lr)\n",
    "\n",
    "            for k in [25, 50, 75, 100, 150]:\n",
    "                self.rmse_values[k] = {}\n",
    "                self.rmse_values[k]['train'] = []\n",
    "                self.rmse_values[k]['test'] = []\n",
    "                self.initialize_factors(ratings_df, k)\n",
    "                print(\"Treniranje na {} faktora\".format(k))\n",
    "                print(str(k), \"faktor, iteracija, train_mse, test_mse, vrijeme\")\n",
    "\n",
    "                test_data, train_data = self.split_data(10, ratings_df)\n",
    "                columns = ['visitorIp', 'objectId', 'counts']\n",
    "                ratings = train_data[columns].to_numpy()\n",
    "                test = test_data[columns].to_numpy()\n",
    "\n",
    "                iterations = 0\n",
    "                index_randomized = random.sample(range(0, len(ratings)), (len(ratings) - 1))\n",
    "\n",
    "                for factor in range(k):\n",
    "                    factor_iteration = 0\n",
    "                    factor_time = datetime.now()\n",
    "\n",
    "                    last_err = sys.maxsize\n",
    "                    last_test_mse = sys.maxsize\n",
    "                    finished = False\n",
    "\n",
    "                    indexes = random.choices(index_randomized, k=math.floor(len(index_randomized) * 0.5))\n",
    "                    while not finished:\n",
    "                        train_mse = self.stocastic_gradient_descent(factor, indexes, ratings)\n",
    "\n",
    "                        iterations += 1\n",
    "                        test_mse = self.calculate_rmse(test, factor)\n",
    "\n",
    "                        finished = self.finished(factor_iteration,\n",
    "                                                last_err,\n",
    "                                                train_mse,\n",
    "                                                last_test_mse,\n",
    "                                                test_mse)\n",
    "\n",
    "                        last_err = train_mse\n",
    "                        last_test_mse = test_mse\n",
    "                        factor_iteration += 1\n",
    "                        self.rmse_values[k]['train'].append(train_mse)\n",
    "                        self.rmse_values[k]['test'].append(test_mse)\n",
    "\n",
    "                self.save(k, False)\n",
    "\n",
    "                ensure_dir('./save/model/'+ str(self.LearnRate*10000).split('.')[0] + '/rmse_values.json')\n",
    "                \n",
    "                with open('./save/model/' + str(self.LearnRate*10000).split('.')[0] + '/rmse_values.json', 'w') as outfile:\n",
    "                    outfile.write(json.dumps(self.rmse_values))\n",
    "            \n",
    "    def calculate_rmse(self, ratings, factor):\n",
    "\n",
    "        def difference(row):\n",
    "            user = self.u_inx[row[0]]\n",
    "            item = self.i_inx[row[1]]\n",
    "\n",
    "            if Decimal(row[2]) > 0.0:\n",
    "              pq = np.dot(self.item_factors[item][:factor + 1], self.user_factors[user][:factor + 1].T)\n",
    "              b_ui = self.user_bias[user] + self.item_bias[item]\n",
    "              prediction = pq + b_ui\n",
    "              MSE = (prediction - Decimal(row[2])) ** 2\n",
    "              return MSE\n",
    "            else:\n",
    "              return 0.0\n",
    "\n",
    "            \n",
    "\n",
    "        squared = np.apply_along_axis(difference, 1, ratings).sum()\n",
    "        n = 0\n",
    "        for x in ratings:\n",
    "            if x[2] > 0:\n",
    "                n += 1\n",
    "        return math.sqrt(squared / n)\n",
    "\n",
    "    def train(self, ratings_df, k=100):\n",
    "\n",
    "        self.initialize_factors(ratings_df, k)\n",
    "\n",
    "        print(\"Treniranje na {} faktora\".format(datetime.now()))\n",
    "\n",
    "        ratings = ratings_df[['visitorIp', 'objectId', 'counts']].to_numpy()\n",
    "\n",
    "        index_randomized = random.sample(range(0, len(ratings)), (len(ratings) - 1))\n",
    "        \n",
    "        for factor in range(k):\n",
    "            factor_time = datetime.now()\n",
    "            iterations = 0\n",
    "            last_err = sys.maxsize\n",
    "            iteration_err = sys.maxsize\n",
    "            finished = False\n",
    "            indexes = random.choices(index_randomized, k=math.floor(len(index_randomized) * 0.5))\n",
    "            \n",
    "            while not finished:\n",
    "                start_time = datetime.now()\n",
    "                iteration_err = self.stocastic_gradient_descent(factor,\n",
    "                                                              indexes,\n",
    "                                                              ratings)\n",
    "\n",
    "\n",
    "                iterations += 1\n",
    "                print(\"epoha u {}, f={}, i={} err={}\".format(datetime.now() - start_time,\n",
    "                                                                       factor,\n",
    "                                                                       iterations,\n",
    "                                                                       iteration_err))\n",
    "                finished = self.finished(iterations,\n",
    "                                         last_err,\n",
    "                                         iteration_err)\n",
    "                last_err = iteration_err\n",
    "            self.save(factor, finished)\n",
    "            print(\"zavrsne faktor {} on f={} i={} err={}\".format(factor,\n",
    "                                                                  datetime.now() - factor_time,\n",
    "                                                                  iterations,\n",
    "                                                                  iteration_err))\n",
    "\n",
    "    def stocastic_gradient_descent(self, factor, index_randomized, ratings):\n",
    "\n",
    "        lr = self.LearnRate\n",
    "        b_lr = self.BiasLearnRate\n",
    "        r = self.Regularization\n",
    "        bias_r = self.BiasReg\n",
    "        self.test = index_randomized\n",
    "        \n",
    "        for inx in index_randomized:\n",
    "\n",
    "\n",
    "            rating_row = ratings[inx]\n",
    "\n",
    "            u = self.u_inx[rating_row[0]]\n",
    "            i = self.i_inx[rating_row[1]]\n",
    "            rating = Decimal(rating_row[2])\n",
    "\n",
    "            if(rating == 0.0):\n",
    "                continue\n",
    "\n",
    "            pred = self.predict(u, i)\n",
    "            err = (rating - pred)\n",
    "\n",
    "            self.user_bias[u] += b_lr * (err - bias_r * self.user_bias[u])\n",
    "            self.item_bias[i] += b_lr * (err - bias_r * self.item_bias[i])\n",
    "\n",
    "            user_fac = self.user_factors[u][factor]\n",
    "            item_fac = self.item_factors[i][factor]\n",
    "\n",
    "            self.user_factors[u][factor] += lr * (err * item_fac - r * user_fac)\n",
    "            self.item_factors[i][factor] += lr * (err * user_fac - r * item_fac)\n",
    "\n",
    "        return self.calculate_rmse(ratings, factor)\n",
    "\n",
    "    def finished(self, iterations, last_err, current_err,\n",
    "                 last_test_mse=0.0, test_mse=0.0):\n",
    "\n",
    "        if last_test_mse < test_mse or iterations >= self.MAX_ITERATIONS or last_err - current_err < 0.0001:\n",
    "            print('ZavrÅ¡eno sa: {} iteracija, diff: {}, last_err: {}, current_err {}, lst_rmse {}, rmse {}'\n",
    "                             .format(iterations, last_err - current_err , last_err, current_err, last_test_mse, test_mse))\n",
    "            return True\n",
    "        else:\n",
    "            self.iterations += 1\n",
    "            return False\n",
    "\n",
    "    def save(self, factor, finished):\n",
    "\n",
    "        save_path = self.save_path + '/model/'\n",
    "        if not finished:\n",
    "            save_path += str(factor) + '_' + str(self.LearnRate*10000).split('.')[0] + '/'\n",
    "\n",
    "        ensure_dir(save_path)\n",
    "\n",
    "        print(\"spremanje faktora u {}\".format(save_path))\n",
    "        user_bias = {str(uid): float(self.user_bias[self.u_inx[uid]]) for uid in self.u_inx.keys()}\n",
    "        item_bias = {str(iid): float(self.item_bias[self.i_inx[iid]]) for iid in self.i_inx.keys()}\n",
    "\n",
    "        uf = pd.DataFrame(self.user_factors,\n",
    "                          index=list(self.user_ids))\n",
    "        it_f = pd.DataFrame(self.item_factors,\n",
    "                            index=list(self.object_ids))\n",
    "\n",
    "        with open(save_path + 'user_factors.json', 'w') as outfile:\n",
    "            outfile.write(uf.to_json())\n",
    "        with open(save_path + 'item_factors.json', 'w') as outfile:\n",
    "            outfile.write(it_f.to_json())\n",
    "        with open(save_path + 'user_bias.json', 'w') as outfile:\n",
    "            json.dump(user_bias, outfile, default = str)\n",
    "        with open(save_path + 'item_bias.json', 'w') as outfile:\n",
    "            json.dump(item_bias, outfile, default = str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF = MatrixFactorization(save_path='./{}'.format('save'), max_iterations=40)\n",
    "MF.train(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
